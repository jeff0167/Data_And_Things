{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install sentence_transformers\n",
    "#!pip install tf-keras\n",
    "#!pip install datasets\n",
    "#!pip install nltk\n",
    "pip install tensorflow[and-cuda]\n",
    "\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 207626.07 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 266629.37 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 325257.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataset to DataFrame\n",
    "def dataset_to_dataframe(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = dataset_to_dataframe(dataset[\"train\"])\n",
    "test_df = dataset_to_dataframe(dataset[\"test\"])\n",
    "\n",
    "\n",
    "# Extract text and labels\n",
    "def preprocess_data(df, sample_size=5000):\n",
    "    df_sample = df.sample(n=sample_size, random_state=42)\n",
    "    texts = df_sample[\"text\"].tolist()\n",
    "    labels = df_sample[\"label\"].tolist()\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = preprocess_data(train_df, sample_size=5000)\n",
    "test_texts, test_labels = preprocess_data(test_df, sample_size=1000)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task:\n",
    "\n",
    "1. Now create embeddings using TFIDF & Transformer model as used in example notebook\n",
    "2. Try some other transformer models from HuggingFace to do embedding - 'microsoft/deberta-v3-large' or 'roberta-large-mnli'\n",
    "2. Train and evaluate models with each embedding separately\n",
    "3. Train a model with all embeddings and evaluate\n",
    "4. Which one is performing the best, why do you think it is the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Now create embeddings using TFIDF & Transformer model as used in example notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all-MiniLM-L6-v2: the best performance, paraphrase-MiniLM-L3-v2: the fastest, very low comparatively performance\n",
    "def model_creater(sentence_transformer):    \n",
    "    model = SentenceTransformer(sentence_transformer) \n",
    "    print(\"Generating transformer embeddings...\")\n",
    "    X_train_transformer = model.encode(train_texts, convert_to_numpy=True)\n",
    "    X_test_transformer = model.encode(test_texts, convert_to_numpy=True)\n",
    "    return X_train_transformer, X_test_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. TF-IDF Features\n",
    "def tf_idf(_max_features=5000):\n",
    "    vectorizer = TfidfVectorizer(max_features=_max_features)\n",
    "    X_train_tfidf = vectorizer.fit_transform(train_texts).toarray()\n",
    "    X_test_tfidf = vectorizer.transform(test_texts).toarray()\n",
    "    return X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scentence transofmrer, different ones, see online\n",
    "### play with the maxfeatures 5000 number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Try some other transformer models from HuggingFace to do embedding - 'microsoft/deberta-v3-large' or 'roberta-large-mnli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating transformer embeddings...\n"
     ]
    }
   ],
   "source": [
    "X_train_transformer, X_test_transformer = model_creater(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformer, X_test_transformer = model_creater(\"paraphrase-MiniLM-L3-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf = tf_idf(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf = tf_idf(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and evaluate models with each embedding separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Models\n",
    "def train_and_evaluate(X_train, X_test, train_labels, test_labels, method):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, train_labels)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(test_labels, y_pred)\n",
    "    report = classification_report(test_labels, y_pred)\n",
    "    print(f\"{method} - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{method} - Classification Report:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating transformer embeddings...\n",
      "Training and evaluating models...\n",
      "Transformer Embeddings - Accuracy: 0.7520\n",
      "Transformer Embeddings - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       511\n",
      "           1       0.74      0.77      0.75       489\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.75      0.75      0.75      1000\n",
      "\n",
      "\n",
      "TF-IDF - Accuracy: 0.8200\n",
      "TF-IDF - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       511\n",
      "           1       0.82      0.81      0.81       489\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.82      0.82      0.82      1000\n",
      "weighted avg       0.82      0.82      0.82      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformer, X_test_transformer = model_creater(\"all-MiniLM-L6-v2\")\n",
    "X_train_tfidf, X_test_tfidf = tf_idf(5000)\n",
    "\n",
    "print(\"Training and evaluating models...\")\n",
    "train_and_evaluate(X_train_transformer, X_test_transformer, train_labels, test_labels, \"Transformer Embeddings\")\n",
    "train_and_evaluate(X_train_tfidf, X_test_tfidf, train_labels, test_labels, \"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating transformer embeddings...\n",
      "Training and evaluating models...\n",
      "Transformer Embeddings - Accuracy: 0.7520\n",
      "Transformer Embeddings - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       511\n",
      "           1       0.74      0.77      0.75       489\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.75      0.75      0.75      1000\n",
      "\n",
      "\n",
      "TF-IDF - Accuracy: 0.8110\n",
      "TF-IDF - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       511\n",
      "           1       0.81      0.81      0.81       489\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformer, X_test_transformer = model_creater(\"all-MiniLM-L6-v2\")\n",
    "X_train_tfidf, X_test_tfidf = tf_idf(1000)\n",
    "\n",
    "print(\"Training and evaluating models...\")\n",
    "train_and_evaluate(X_train_transformer, X_test_transformer, train_labels, test_labels, \"Transformer Embeddings\")\n",
    "train_and_evaluate(X_train_tfidf, X_test_tfidf, train_labels, test_labels, \"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformer, X_test_transformer = model_creater(\"paraphrase-MiniLM-L3-v2\")\n",
    "X_train_tfidf, X_test_tfidf = tf_idf(5000)\n",
    "\n",
    "print(\"Training and evaluating models...\")\n",
    "train_and_evaluate(X_train_transformer, X_test_transformer, train_labels, test_labels, \"Transformer Embeddings\")\n",
    "train_and_evaluate(X_train_tfidf, X_test_tfidf, train_labels, test_labels, \"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformer, X_test_transformer = model_creater(\"paraphrase-MiniLM-L3-v2\")\n",
    "X_train_tfidf, X_test_tfidf = tf_idf(1000)\n",
    "\n",
    "print(\"Training and evaluating models...\")\n",
    "train_and_evaluate(X_train_transformer, X_test_transformer, train_labels, test_labels, \"Transformer Embeddings\")\n",
    "train_and_evaluate(X_train_tfidf, X_test_tfidf, train_labels, test_labels, \"TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train a model with all embeddings and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Which one is performing the best, why do you think it is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note azure open ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
