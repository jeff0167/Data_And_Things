{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execise 1\n",
    "\n",
    "In this exercise, do the following:\n",
    "1. Load the dataset used in the time series example - Energy consumption data. You can find it in the notebook \"TSA_Example\" in Time Series folder in Moodle.\n",
    "2. Setup a nested MLFlow loop where different modelling experiments can be tracked and then use the dataset in point 1 to experiment and track models. You should do following combinations:\n",
    "    1. At least 3 model types\n",
    "    2. At least 3 different feature combinations\n",
    "    3. At least 3 different options for 3 different hyperparameters\n",
    "    4. At least 3 different time splits for train test\n",
    "3. For each option in the combination, you should calculate & log the following in MLFlow:\n",
    "    1. RMSE\n",
    "    2. MAE\n",
    "    3. Plot of actual vs predicted for 1 month data\n",
    "    4. Plot of actual vs predicted for 1 week of data\n",
    "    5. All of the combination info in point 2, such as which model, what feature combindation, what hyperparameter, what train test split has been used\n",
    "4. Turn on MLFlow UI and track your experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the dataset used in the time series example - Energy consumption data. You can find it in the notebook \"TSA_Example\" in Time Series folder in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Bruger\\.cache\\kagglehub\\datasets\\robikscube\\hourly-energy-consumption\\versions\\3\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"robikscube/hourly-energy-consumption\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AEP_hourly.csv', 'COMED_hourly.csv', 'DAYTON_hourly.csv', 'DEOK_hourly.csv', 'DOM_hourly.csv', 'DUQ_hourly.csv', 'EKPC_hourly.csv', 'est_hourly.paruqet', 'FE_hourly.csv', 'NI_hourly.csv', 'PJME_hourly.csv', 'PJMW_hourly.csv', 'pjm_hourly_est.csv', 'PJM_Load_hourly.csv']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"C:/Users/bruger/.cache/kagglehub/datasets/robikscube/hourly-energy-consumption/versions/3\"\n",
    "\n",
    "files = os.listdir(dataset_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/bruger/.cache/kagglehub/datasets/robikscube/hourly-energy-consumption/versions/3/PJME_hourly.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df = df.set_index('Datetime')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mlflow_startup_interface.ipynb # it won't let me import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting MLFlow UI...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[Open MLFlow UI](http://localhost:5000)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFlow UI is running at http://localhost:5000. Press Ctrl+C in the terminal to stop it.\n"
     ]
    }
   ],
   "source": [
    "start_mlflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01 01:00:00</th>\n",
       "      <td>30393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 02:00:00</th>\n",
       "      <td>29265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 03:00:00</th>\n",
       "      <td>28357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 04:00:00</th>\n",
       "      <td>27899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 05:00:00</th>\n",
       "      <td>28057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 20:00:00</th>\n",
       "      <td>44057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 21:00:00</th>\n",
       "      <td>43256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 22:00:00</th>\n",
       "      <td>41552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 23:00:00</th>\n",
       "      <td>38500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03 00:00:00</th>\n",
       "      <td>35486.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145366 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW\n",
       "Datetime                    \n",
       "2002-01-01 01:00:00  30393.0\n",
       "2002-01-01 02:00:00  29265.0\n",
       "2002-01-01 03:00:00  28357.0\n",
       "2002-01-01 04:00:00  27899.0\n",
       "2002-01-01 05:00:00  28057.0\n",
       "...                      ...\n",
       "2018-08-02 20:00:00  44057.0\n",
       "2018-08-02 21:00:00  43256.0\n",
       "2018-08-02 22:00:00  41552.0\n",
       "2018-08-02 23:00:00  38500.0\n",
       "2018-08-03 00:00:00  35486.0\n",
       "\n",
       "[145366 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup a nested MLFlow loop where different modelling experiments can be tracked and then use the dataset in point 1 to experiment and track models. You should do following combinations:\n",
    "\n",
    "    At least 3 model types\n",
    "    At least 3 different feature combinations\n",
    "    At least 3 different options for 3 different hyperparameters\n",
    "    At least 3 different time splits for train test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create time series features and lag features based on time series index.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Basic time-based features\n",
    "    df['hour'] = df.index.hour\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['weekofyear'] = df.index.isocalendar().week\n",
    "\n",
    "    # Lag features\n",
    "    df['lag_1d'] = df['PJME_MW'].shift(1)   # 1 day lag\n",
    "    df['lag_1w'] = df['PJME_MW'].shift(7)   # 1 week lag\n",
    "    df['lag_1m'] = df['PJME_MW'].shift(30)  # 1 month lag (approx. 30 days)\n",
    "    df['lag_1y'] = df['PJME_MW'].shift(365) # 1 year lag\n",
    "\n",
    "    # Rolling statistics features\n",
    "    df['rolling_mean_3d'] = df['PJME_MW'].rolling(window=3).mean()  # Last 3 days rolling mean\n",
    "    df['rolling_mean_30d'] = df['PJME_MW'].rolling(window=30).mean()  # Last month rolling mean\n",
    "    df['rolling_mean_same_month_last_year'] = df['PJME_MW'].shift(365).rolling(window=30).mean()  # Same month previous year rolling mean\n",
    "    df['rolling_mean_same_week_last_year'] = df['PJME_MW'].shift(365).rolling(window=7).mean()  # Same week previous year rolling mean\n",
    "\n",
    "    return df\n",
    "\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>lag_1d</th>\n",
       "      <th>lag_1w</th>\n",
       "      <th>lag_1m</th>\n",
       "      <th>lag_1y</th>\n",
       "      <th>rolling_mean_3d</th>\n",
       "      <th>rolling_mean_30d</th>\n",
       "      <th>rolling_mean_same_month_last_year</th>\n",
       "      <th>rolling_mean_same_week_last_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-17 11:00:00</th>\n",
       "      <td>34115.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>34638.0</td>\n",
       "      <td>25708.0</td>\n",
       "      <td>26174.0</td>\n",
       "      <td>30748.0</td>\n",
       "      <td>34485.333333</td>\n",
       "      <td>32294.733333</td>\n",
       "      <td>30465.500000</td>\n",
       "      <td>28444.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-17 12:00:00</th>\n",
       "      <td>33835.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>34115.0</td>\n",
       "      <td>26130.0</td>\n",
       "      <td>28361.0</td>\n",
       "      <td>34725.0</td>\n",
       "      <td>34196.000000</td>\n",
       "      <td>32477.200000</td>\n",
       "      <td>30609.900000</td>\n",
       "      <td>29181.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-17 13:00:00</th>\n",
       "      <td>33368.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>33835.0</td>\n",
       "      <td>28123.0</td>\n",
       "      <td>32443.0</td>\n",
       "      <td>37313.0</td>\n",
       "      <td>33772.666667</td>\n",
       "      <td>32508.033333</td>\n",
       "      <td>30878.166667</td>\n",
       "      <td>30494.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-17 14:00:00</th>\n",
       "      <td>33152.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>33368.0</td>\n",
       "      <td>32359.0</td>\n",
       "      <td>34902.0</td>\n",
       "      <td>37322.0</td>\n",
       "      <td>33451.666667</td>\n",
       "      <td>32449.700000</td>\n",
       "      <td>31177.000000</td>\n",
       "      <td>31906.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-17 15:00:00</th>\n",
       "      <td>32662.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>33152.0</td>\n",
       "      <td>34860.0</td>\n",
       "      <td>34752.0</td>\n",
       "      <td>37035.0</td>\n",
       "      <td>33060.666667</td>\n",
       "      <td>32380.033333</td>\n",
       "      <td>31481.533333</td>\n",
       "      <td>33297.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 20:00:00</th>\n",
       "      <td>44057.0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>45641.0</td>\n",
       "      <td>45372.0</td>\n",
       "      <td>45313.0</td>\n",
       "      <td>42771.0</td>\n",
       "      <td>45486.000000</td>\n",
       "      <td>41515.666667</td>\n",
       "      <td>38934.233333</td>\n",
       "      <td>38711.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 21:00:00</th>\n",
       "      <td>43256.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>44057.0</td>\n",
       "      <td>46534.0</td>\n",
       "      <td>46430.0</td>\n",
       "      <td>43742.0</td>\n",
       "      <td>44318.000000</td>\n",
       "      <td>41409.866667</td>\n",
       "      <td>38948.666667</td>\n",
       "      <td>40083.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 22:00:00</th>\n",
       "      <td>41552.0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>43256.0</td>\n",
       "      <td>47154.0</td>\n",
       "      <td>47867.0</td>\n",
       "      <td>44607.0</td>\n",
       "      <td>42955.000000</td>\n",
       "      <td>41199.366667</td>\n",
       "      <td>38906.000000</td>\n",
       "      <td>41346.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 23:00:00</th>\n",
       "      <td>38500.0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>41552.0</td>\n",
       "      <td>46989.0</td>\n",
       "      <td>48855.0</td>\n",
       "      <td>45057.0</td>\n",
       "      <td>41102.666667</td>\n",
       "      <td>40854.200000</td>\n",
       "      <td>38805.866667</td>\n",
       "      <td>42449.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03 00:00:00</th>\n",
       "      <td>35486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>215</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>38500.0</td>\n",
       "      <td>46816.0</td>\n",
       "      <td>49308.0</td>\n",
       "      <td>44294.0</td>\n",
       "      <td>38512.666667</td>\n",
       "      <td>40393.466667</td>\n",
       "      <td>38629.466667</td>\n",
       "      <td>43215.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144972 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW  hour  dayofweek  quarter  month  year  \\\n",
       "Datetime                                                              \n",
       "2002-01-17 11:00:00  34115.0    11          3        1      1  2002   \n",
       "2002-01-17 12:00:00  33835.0    12          3        1      1  2002   \n",
       "2002-01-17 13:00:00  33368.0    13          3        1      1  2002   \n",
       "2002-01-17 14:00:00  33152.0    14          3        1      1  2002   \n",
       "2002-01-17 15:00:00  32662.0    15          3        1      1  2002   \n",
       "...                      ...   ...        ...      ...    ...   ...   \n",
       "2018-08-02 20:00:00  44057.0    20          3        3      8  2018   \n",
       "2018-08-02 21:00:00  43256.0    21          3        3      8  2018   \n",
       "2018-08-02 22:00:00  41552.0    22          3        3      8  2018   \n",
       "2018-08-02 23:00:00  38500.0    23          3        3      8  2018   \n",
       "2018-08-03 00:00:00  35486.0     0          4        3      8  2018   \n",
       "\n",
       "                     dayofyear  dayofmonth  weekofyear   lag_1d   lag_1w  \\\n",
       "Datetime                                                                   \n",
       "2002-01-17 11:00:00         17          17           3  34638.0  25708.0   \n",
       "2002-01-17 12:00:00         17          17           3  34115.0  26130.0   \n",
       "2002-01-17 13:00:00         17          17           3  33835.0  28123.0   \n",
       "2002-01-17 14:00:00         17          17           3  33368.0  32359.0   \n",
       "2002-01-17 15:00:00         17          17           3  33152.0  34860.0   \n",
       "...                        ...         ...         ...      ...      ...   \n",
       "2018-08-02 20:00:00        214           2          31  45641.0  45372.0   \n",
       "2018-08-02 21:00:00        214           2          31  44057.0  46534.0   \n",
       "2018-08-02 22:00:00        214           2          31  43256.0  47154.0   \n",
       "2018-08-02 23:00:00        214           2          31  41552.0  46989.0   \n",
       "2018-08-03 00:00:00        215           3          31  38500.0  46816.0   \n",
       "\n",
       "                      lag_1m   lag_1y  rolling_mean_3d  rolling_mean_30d  \\\n",
       "Datetime                                                                   \n",
       "2002-01-17 11:00:00  26174.0  30748.0     34485.333333      32294.733333   \n",
       "2002-01-17 12:00:00  28361.0  34725.0     34196.000000      32477.200000   \n",
       "2002-01-17 13:00:00  32443.0  37313.0     33772.666667      32508.033333   \n",
       "2002-01-17 14:00:00  34902.0  37322.0     33451.666667      32449.700000   \n",
       "2002-01-17 15:00:00  34752.0  37035.0     33060.666667      32380.033333   \n",
       "...                      ...      ...              ...               ...   \n",
       "2018-08-02 20:00:00  45313.0  42771.0     45486.000000      41515.666667   \n",
       "2018-08-02 21:00:00  46430.0  43742.0     44318.000000      41409.866667   \n",
       "2018-08-02 22:00:00  47867.0  44607.0     42955.000000      41199.366667   \n",
       "2018-08-02 23:00:00  48855.0  45057.0     41102.666667      40854.200000   \n",
       "2018-08-03 00:00:00  49308.0  44294.0     38512.666667      40393.466667   \n",
       "\n",
       "                     rolling_mean_same_month_last_year  \\\n",
       "Datetime                                                 \n",
       "2002-01-17 11:00:00                       30465.500000   \n",
       "2002-01-17 12:00:00                       30609.900000   \n",
       "2002-01-17 13:00:00                       30878.166667   \n",
       "2002-01-17 14:00:00                       31177.000000   \n",
       "2002-01-17 15:00:00                       31481.533333   \n",
       "...                                                ...   \n",
       "2018-08-02 20:00:00                       38934.233333   \n",
       "2018-08-02 21:00:00                       38948.666667   \n",
       "2018-08-02 22:00:00                       38906.000000   \n",
       "2018-08-02 23:00:00                       38805.866667   \n",
       "2018-08-03 00:00:00                       38629.466667   \n",
       "\n",
       "                     rolling_mean_same_week_last_year  \n",
       "Datetime                                               \n",
       "2002-01-17 11:00:00                      28444.000000  \n",
       "2002-01-17 12:00:00                      29181.428571  \n",
       "2002-01-17 13:00:00                      30494.571429  \n",
       "2002-01-17 14:00:00                      31906.714286  \n",
       "2002-01-17 15:00:00                      33297.285714  \n",
       "...                                               ...  \n",
       "2018-08-02 20:00:00                      38711.142857  \n",
       "2018-08-02 21:00:00                      40083.428571  \n",
       "2018-08-02 22:00:00                      41346.428571  \n",
       "2018-08-02 23:00:00                      42449.000000  \n",
       "2018-08-03 00:00:00                      43215.714286  \n",
       "\n",
       "[144972 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df.drop(columns = [\"PJME_MW\"])\n",
    "y = df['PJME_MW']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42)\n",
    "\n",
    "# Define different feature combinations\n",
    "feature_combinations = [\n",
    "    X.columns[:2],  # First two features\n",
    "    X.columns[2:],  # Last two features\n",
    "    X.columns[2:9]       # All features\n",
    "]\n",
    "\n",
    "time_split = ['06-1-2002', '01-01-2003', '06-01-2003'] # train at home with higher values, m/d/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2002-01-17 11:00:00')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-08-03 00:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/03/12 14:37:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/03/12 14:38:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/03/12 14:39:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/03/12 14:40:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/03/12 14:45:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/03/12 14:54:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Bruger\\anaconda3\\envs\\python_3_10_16\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start MLFlow experiment\n",
    "mlflow.set_experiment(\"MLFlow Energy Consumption data\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Train models with different feature combinations\n",
    "for features in feature_combinations:\n",
    "    for model_name, model in zip([\"RandomForest\", \"LogisticRegression\"],\n",
    "                                 [RandomForestClassifier(random_state=42), LogisticRegression(max_iter=200)]):\n",
    "        with mlflow.start_run():\n",
    "            # Log feature combination and model type\n",
    "            mlflow.log_param(\"features\", features)\n",
    "            mlflow.log_param(\"model_type\", model_name)\n",
    "\n",
    "            for split in time_split:\n",
    "                    \n",
    "                # Train test split\n",
    "                X_train = X.loc[X.index < split]\n",
    "                y_train = y.loc[y.index < split]\n",
    "\n",
    "                X_test = X.loc[(X.index >= split) & (X.index < '01-01-2004')]\n",
    "                y_test = y.loc[(y.index >= split) & (y.index < '01-01-2004')]\n",
    "                \n",
    "                #X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.2, random_state=42)\n",
    "                \n",
    "                # Train the model\n",
    "                model.fit(X_train[features], y_train)\n",
    "                predictions = model.predict(X_test[features])\n",
    "                \n",
    "                # Calculate metrics\n",
    "                accuracy = accuracy_score(y_test, predictions)\n",
    "                precision = precision_score(y_test, predictions, average='weighted')\n",
    "                recall = recall_score(y_test, predictions, average='weighted')\n",
    "                f1 = f1_score(y_test, predictions, average='weighted')\n",
    "                \n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_metric(\"precision\", precision)\n",
    "                mlflow.log_metric(\"recall\", recall)\n",
    "                mlflow.log_metric(\"f1_score\", f1)\n",
    "                \n",
    "                # Create and log a plot of the metrics\n",
    "                fig, ax = plt.subplots(figsize=(8, 4))\n",
    "                metrics = [accuracy, precision, recall, f1]\n",
    "                metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "                ax.bar(metric_names, metrics, color='skyblue')\n",
    "                ax.set_title(f\"{model_name} Metrics for Feature Set: {features}\")\n",
    "                ax.set_ylim(0, 1)\n",
    "                \n",
    "                # Save the plot to a temporary file and log it as an artifact\n",
    "                temp_file = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
    "                plt.savefig(temp_file.name)\n",
    "                mlflow.log_artifact(temp_file.name, artifact_path=\"plots\")\n",
    "                temp_file.close()\n",
    "                \n",
    "                # Log the model\n",
    "                mlflow.sklearn.log_model(model, model_name)\n",
    "                \n",
    "                # Store results for summary\n",
    "                results.append({\n",
    "                    \"features\": features,\n",
    "                    \"model\": model_name,\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"f1_score\": f1\n",
    "                })\n",
    "\n",
    "# Print summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Experiment Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each option in the combination, you should calculate & log the following in MLFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3_10_16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
