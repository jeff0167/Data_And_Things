{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execise 1\n",
    "\n",
    "In this exercise, do the following:\n",
    "1. Load the dataset used in the time series example - Energy consumption data. You can find it in the notebook \"TSA_Example\" in Time Series folder in Moodle.\n",
    "2. Setup a nested MLFlow loop where different modelling experiments can be tracked and then use the dataset in point 1 to experiment and track models. You should do following combinations:\n",
    "    1. At least 3 model types\n",
    "    2. At least 3 different feature combinations\n",
    "    3. At least 3 different options for 3 different hyperparameters\n",
    "    4. At least 3 different time splits for train test\n",
    "3. For each option in the combination, you should calculate & log the following in MLFlow:\n",
    "    1. RMSE\n",
    "    2. MAE\n",
    "    3. Plot of actual vs predicted for 1 month data\n",
    "    4. Plot of actual vs predicted for 1 week of data\n",
    "    5. All of the combination info in point 2, such as which model, what feature combindation, what hyperparameter, what train test split has been used\n",
    "4. Turn on MLFlow UI and track your experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the dataset used in the time series example - Energy consumption data. You can find it in the notebook \"TSA_Example\" in Time Series folder in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.10)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/robikscube/hourly-energy-consumption?dataset_version_number=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 11.4M/11.4M [00:01<00:00, 11.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Bruger\\.cache\\kagglehub\\datasets\\robikscube\\hourly-energy-consumption\\versions\\3\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"robikscube/hourly-energy-consumption\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AEP_hourly.csv', 'COMED_hourly.csv', 'DAYTON_hourly.csv', 'DEOK_hourly.csv', 'DOM_hourly.csv', 'DUQ_hourly.csv', 'EKPC_hourly.csv', 'est_hourly.paruqet', 'FE_hourly.csv', 'NI_hourly.csv', 'PJME_hourly.csv', 'PJMW_hourly.csv', 'pjm_hourly_est.csv', 'PJM_Load_hourly.csv']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"C:/Users/bruger/.cache/kagglehub/datasets/robikscube/hourly-energy-consumption/versions/3\"\n",
    "\n",
    "files = os.listdir(dataset_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/bruger/.cache/kagglehub/datasets/robikscube/hourly-energy-consumption/versions/3/PJME_hourly.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df = df.set_index('Datetime')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mlflow_startup_interface.ipynb # it won't let me import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting MLFlow UI...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[Open MLFlow UI](http://localhost:5000)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFlow UI is running at http://localhost:5000. Press Ctrl+C in the terminal to stop it.\n"
     ]
    }
   ],
   "source": [
    "start_mlflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01 01:00:00</th>\n",
       "      <td>30393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 02:00:00</th>\n",
       "      <td>29265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 03:00:00</th>\n",
       "      <td>28357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 04:00:00</th>\n",
       "      <td>27899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 05:00:00</th>\n",
       "      <td>28057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 20:00:00</th>\n",
       "      <td>44057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 21:00:00</th>\n",
       "      <td>43256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 22:00:00</th>\n",
       "      <td>41552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 23:00:00</th>\n",
       "      <td>38500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03 00:00:00</th>\n",
       "      <td>35486.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145366 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW\n",
       "Datetime                    \n",
       "2002-01-01 01:00:00  30393.0\n",
       "2002-01-01 02:00:00  29265.0\n",
       "2002-01-01 03:00:00  28357.0\n",
       "2002-01-01 04:00:00  27899.0\n",
       "2002-01-01 05:00:00  28057.0\n",
       "...                      ...\n",
       "2018-08-02 20:00:00  44057.0\n",
       "2018-08-02 21:00:00  43256.0\n",
       "2018-08-02 22:00:00  41552.0\n",
       "2018-08-02 23:00:00  38500.0\n",
       "2018-08-03 00:00:00  35486.0\n",
       "\n",
       "[145366 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup a nested MLFlow loop where different modelling experiments can be tracked and then use the dataset in point 1 to experiment and track models. You should do following combinations:\n",
    "\n",
    "    At least 3 model types\n",
    "    At least 3 different feature combinations\n",
    "    At least 3 different options for 3 different hyperparameters\n",
    "    At least 3 different time splits for train test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create time series features and lag features based on time series index.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Basic time-based features\n",
    "    df['hour'] = df.index.hour\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['weekofyear'] = df.index.isocalendar().week\n",
    "\n",
    "    # Lag features\n",
    "    df['lag_1d'] = df['PJME_MW'].shift(1)   # 1 day lag\n",
    "    df['lag_1w'] = df['PJME_MW'].shift(7)   # 1 week lag\n",
    "    df['lag_1m'] = df['PJME_MW'].shift(30)  # 1 month lag (approx. 30 days)\n",
    "    df['lag_1y'] = df['PJME_MW'].shift(365) # 1 year lag\n",
    "\n",
    "    # Rolling statistics features\n",
    "    df['rolling_mean_3d'] = df['PJME_MW'].rolling(window=3).mean()  # Last 3 days rolling mean\n",
    "    df['rolling_mean_30d'] = df['PJME_MW'].rolling(window=30).mean()  # Last month rolling mean\n",
    "    df['rolling_mean_same_month_last_year'] = df['PJME_MW'].shift(365).rolling(window=30).mean()  # Same month previous year rolling mean\n",
    "    df['rolling_mean_same_week_last_year'] = df['PJME_MW'].shift(365).rolling(window=7).mean()  # Same week previous year rolling mean\n",
    "\n",
    "    return df\n",
    "\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>lag_1d</th>\n",
       "      <th>lag_1w</th>\n",
       "      <th>lag_1m</th>\n",
       "      <th>lag_1y</th>\n",
       "      <th>rolling_mean_3d</th>\n",
       "      <th>rolling_mean_30d</th>\n",
       "      <th>rolling_mean_same_month_last_year</th>\n",
       "      <th>rolling_mean_same_week_last_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-17 11:00:00</th>\n",
       "      <td>34115.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>34638.0</td>\n",
       "      <td>25708.0</td>\n",
       "      <td>26174.0</td>\n",
       "      <td>30748.0</td>\n",
       "      <td>34485.333333</td>\n",
       "      <td>32294.733333</td>\n",
       "      <td>30465.500000</td>\n",
       "      <td>28444.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-17 12:00:00</th>\n",
       "      <td>33835.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>34115.0</td>\n",
       "      <td>26130.0</td>\n",
       "      <td>28361.0</td>\n",
       "      <td>34725.0</td>\n",
       "      <td>34196.000000</td>\n",
       "      <td>32477.200000</td>\n",
       "      <td>30609.900000</td>\n",
       "      <td>29181.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-17 13:00:00</th>\n",
       "      <td>33368.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>33835.0</td>\n",
       "      <td>28123.0</td>\n",
       "      <td>32443.0</td>\n",
       "      <td>37313.0</td>\n",
       "      <td>33772.666667</td>\n",
       "      <td>32508.033333</td>\n",
       "      <td>30878.166667</td>\n",
       "      <td>30494.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-17 14:00:00</th>\n",
       "      <td>33152.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>33368.0</td>\n",
       "      <td>32359.0</td>\n",
       "      <td>34902.0</td>\n",
       "      <td>37322.0</td>\n",
       "      <td>33451.666667</td>\n",
       "      <td>32449.700000</td>\n",
       "      <td>31177.000000</td>\n",
       "      <td>31906.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-17 15:00:00</th>\n",
       "      <td>32662.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>33152.0</td>\n",
       "      <td>34860.0</td>\n",
       "      <td>34752.0</td>\n",
       "      <td>37035.0</td>\n",
       "      <td>33060.666667</td>\n",
       "      <td>32380.033333</td>\n",
       "      <td>31481.533333</td>\n",
       "      <td>33297.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 20:00:00</th>\n",
       "      <td>44057.0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>45641.0</td>\n",
       "      <td>45372.0</td>\n",
       "      <td>45313.0</td>\n",
       "      <td>42771.0</td>\n",
       "      <td>45486.000000</td>\n",
       "      <td>41515.666667</td>\n",
       "      <td>38934.233333</td>\n",
       "      <td>38711.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 21:00:00</th>\n",
       "      <td>43256.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>44057.0</td>\n",
       "      <td>46534.0</td>\n",
       "      <td>46430.0</td>\n",
       "      <td>43742.0</td>\n",
       "      <td>44318.000000</td>\n",
       "      <td>41409.866667</td>\n",
       "      <td>38948.666667</td>\n",
       "      <td>40083.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 22:00:00</th>\n",
       "      <td>41552.0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>43256.0</td>\n",
       "      <td>47154.0</td>\n",
       "      <td>47867.0</td>\n",
       "      <td>44607.0</td>\n",
       "      <td>42955.000000</td>\n",
       "      <td>41199.366667</td>\n",
       "      <td>38906.000000</td>\n",
       "      <td>41346.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02 23:00:00</th>\n",
       "      <td>38500.0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>41552.0</td>\n",
       "      <td>46989.0</td>\n",
       "      <td>48855.0</td>\n",
       "      <td>45057.0</td>\n",
       "      <td>41102.666667</td>\n",
       "      <td>40854.200000</td>\n",
       "      <td>38805.866667</td>\n",
       "      <td>42449.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03 00:00:00</th>\n",
       "      <td>35486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>215</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>38500.0</td>\n",
       "      <td>46816.0</td>\n",
       "      <td>49308.0</td>\n",
       "      <td>44294.0</td>\n",
       "      <td>38512.666667</td>\n",
       "      <td>40393.466667</td>\n",
       "      <td>38629.466667</td>\n",
       "      <td>43215.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144972 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PJME_MW  hour  dayofweek  quarter  month  year  \\\n",
       "Datetime                                                              \n",
       "2002-01-17 11:00:00  34115.0    11          3        1      1  2002   \n",
       "2002-01-17 12:00:00  33835.0    12          3        1      1  2002   \n",
       "2002-01-17 13:00:00  33368.0    13          3        1      1  2002   \n",
       "2002-01-17 14:00:00  33152.0    14          3        1      1  2002   \n",
       "2002-01-17 15:00:00  32662.0    15          3        1      1  2002   \n",
       "...                      ...   ...        ...      ...    ...   ...   \n",
       "2018-08-02 20:00:00  44057.0    20          3        3      8  2018   \n",
       "2018-08-02 21:00:00  43256.0    21          3        3      8  2018   \n",
       "2018-08-02 22:00:00  41552.0    22          3        3      8  2018   \n",
       "2018-08-02 23:00:00  38500.0    23          3        3      8  2018   \n",
       "2018-08-03 00:00:00  35486.0     0          4        3      8  2018   \n",
       "\n",
       "                     dayofyear  dayofmonth  weekofyear   lag_1d   lag_1w  \\\n",
       "Datetime                                                                   \n",
       "2002-01-17 11:00:00         17          17           3  34638.0  25708.0   \n",
       "2002-01-17 12:00:00         17          17           3  34115.0  26130.0   \n",
       "2002-01-17 13:00:00         17          17           3  33835.0  28123.0   \n",
       "2002-01-17 14:00:00         17          17           3  33368.0  32359.0   \n",
       "2002-01-17 15:00:00         17          17           3  33152.0  34860.0   \n",
       "...                        ...         ...         ...      ...      ...   \n",
       "2018-08-02 20:00:00        214           2          31  45641.0  45372.0   \n",
       "2018-08-02 21:00:00        214           2          31  44057.0  46534.0   \n",
       "2018-08-02 22:00:00        214           2          31  43256.0  47154.0   \n",
       "2018-08-02 23:00:00        214           2          31  41552.0  46989.0   \n",
       "2018-08-03 00:00:00        215           3          31  38500.0  46816.0   \n",
       "\n",
       "                      lag_1m   lag_1y  rolling_mean_3d  rolling_mean_30d  \\\n",
       "Datetime                                                                   \n",
       "2002-01-17 11:00:00  26174.0  30748.0     34485.333333      32294.733333   \n",
       "2002-01-17 12:00:00  28361.0  34725.0     34196.000000      32477.200000   \n",
       "2002-01-17 13:00:00  32443.0  37313.0     33772.666667      32508.033333   \n",
       "2002-01-17 14:00:00  34902.0  37322.0     33451.666667      32449.700000   \n",
       "2002-01-17 15:00:00  34752.0  37035.0     33060.666667      32380.033333   \n",
       "...                      ...      ...              ...               ...   \n",
       "2018-08-02 20:00:00  45313.0  42771.0     45486.000000      41515.666667   \n",
       "2018-08-02 21:00:00  46430.0  43742.0     44318.000000      41409.866667   \n",
       "2018-08-02 22:00:00  47867.0  44607.0     42955.000000      41199.366667   \n",
       "2018-08-02 23:00:00  48855.0  45057.0     41102.666667      40854.200000   \n",
       "2018-08-03 00:00:00  49308.0  44294.0     38512.666667      40393.466667   \n",
       "\n",
       "                     rolling_mean_same_month_last_year  \\\n",
       "Datetime                                                 \n",
       "2002-01-17 11:00:00                       30465.500000   \n",
       "2002-01-17 12:00:00                       30609.900000   \n",
       "2002-01-17 13:00:00                       30878.166667   \n",
       "2002-01-17 14:00:00                       31177.000000   \n",
       "2002-01-17 15:00:00                       31481.533333   \n",
       "...                                                ...   \n",
       "2018-08-02 20:00:00                       38934.233333   \n",
       "2018-08-02 21:00:00                       38948.666667   \n",
       "2018-08-02 22:00:00                       38906.000000   \n",
       "2018-08-02 23:00:00                       38805.866667   \n",
       "2018-08-03 00:00:00                       38629.466667   \n",
       "\n",
       "                     rolling_mean_same_week_last_year  \n",
       "Datetime                                               \n",
       "2002-01-17 11:00:00                      28444.000000  \n",
       "2002-01-17 12:00:00                      29181.428571  \n",
       "2002-01-17 13:00:00                      30494.571429  \n",
       "2002-01-17 14:00:00                      31906.714286  \n",
       "2002-01-17 15:00:00                      33297.285714  \n",
       "...                                               ...  \n",
       "2018-08-02 20:00:00                      38711.142857  \n",
       "2018-08-02 21:00:00                      40083.428571  \n",
       "2018-08-02 22:00:00                      41346.428571  \n",
       "2018-08-02 23:00:00                      42449.000000  \n",
       "2018-08-03 00:00:00                      43215.714286  \n",
       "\n",
       "[144972 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df\n",
    "y = df['PJME_MW']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42)\n",
    "\n",
    "# Define different feature combinations\n",
    "feature_combinations = [\n",
    "    iris.feature_names[:2],  # First two features\n",
    "    iris.feature_names[2:],  # Last two features\n",
    "    iris.feature_names       # All features\n",
    "]\n",
    "\n",
    "time_split = ['01-01-2015', '01-01-2016', '01-01-2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start MLFlow experiment\n",
    "mlflow.set_experiment(\"MLFlow Energy Consumption data\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Train models with different feature combinations\n",
    "for features in feature_combinations:\n",
    "    for model_name, model in zip([\"RandomForest\", \"LogisticRegression\"], \n",
    "                                 [RandomForestClassifier(random_state=42), LogisticRegression(max_iter=200)]):\n",
    "        with mlflow.start_run():\n",
    "            # Log feature combination and model type\n",
    "            mlflow.log_param(\"features\", features)\n",
    "            mlflow.log_param(\"model_type\", model_name)\n",
    "\n",
    "            for split in time_split:\n",
    "                    \n",
    "                # Train test split\n",
    "                train = X.loc[X.index < split]\n",
    "                test = X.loc[X.index >= split]\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.2, random_state=42)\n",
    "                \n",
    "                # Train the model\n",
    "                model.fit(X_train[features], y_train)\n",
    "                predictions = model.predict(X_test[features])\n",
    "                \n",
    "                # Calculate metrics\n",
    "                accuracy = accuracy_score(y_test, predictions)\n",
    "                precision = precision_score(y_test, predictions, average='weighted')\n",
    "                recall = recall_score(y_test, predictions, average='weighted')\n",
    "                f1 = f1_score(y_test, predictions, average='weighted')\n",
    "                \n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_metric(\"precision\", precision)\n",
    "                mlflow.log_metric(\"recall\", recall)\n",
    "                mlflow.log_metric(\"f1_score\", f1)\n",
    "                \n",
    "                # Create and log a plot of the metrics\n",
    "                fig, ax = plt.subplots(figsize=(8, 4))\n",
    "                metrics = [accuracy, precision, recall, f1]\n",
    "                metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "                ax.bar(metric_names, metrics, color='skyblue')\n",
    "                ax.set_title(f\"{model_name} Metrics for Feature Set: {features}\")\n",
    "                ax.set_ylim(0, 1)\n",
    "                \n",
    "                # Save the plot to a temporary file and log it as an artifact\n",
    "                temp_file = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
    "                plt.savefig(temp_file.name)\n",
    "                mlflow.log_artifact(temp_file.name, artifact_path=\"plots\")\n",
    "                temp_file.close()\n",
    "                \n",
    "                # Log the model\n",
    "                mlflow.sklearn.log_model(model, model_name)\n",
    "                \n",
    "                # Store results for summary\n",
    "                results.append({\n",
    "                    \"features\": features,\n",
    "                    \"model\": model_name,\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"f1_score\": f1\n",
    "                })\n",
    "\n",
    "# Print summary of results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Experiment Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each option in the combination, you should calculate & log the following in MLFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
